{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Vector-dot-and-cross-products\" data-toc-modified-id=\"Vector-dot-and-cross-products-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Vector dot and cross products</a></span><ul class=\"toc-item\"><li><span><a href=\"#Vector-Dot-product:\" data-toc-modified-id=\"Vector-Dot-product:-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Vector Dot product:</a></span></li><li><span><a href=\"#Vector-Length:\" data-toc-modified-id=\"Vector-Length:-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Vector Length:</a></span></li><li><span><a href=\"#Vector-Dot-Product-Rules:\" data-toc-modified-id=\"Vector-Dot-Product-Rules:-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Vector Dot Product Rules:</a></span></li><li><span><a href=\"#Cauchy-Schwarz-inequality\" data-toc-modified-id=\"Cauchy-Schwarz-inequality-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Cauchy-Schwarz inequality</a></span></li><li><span><a href=\"#Triangle-Inequality\" data-toc-modified-id=\"Triangle-Inequality-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Triangle Inequality</a></span></li><li><span><a href=\"#Angle-b/w-2-vectors.\" data-toc-modified-id=\"Angle-b/w-2-vectors.-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>Angle b/w 2 vectors.</a></span></li><li><span><a href=\"#Cross-Product\" data-toc-modified-id=\"Cross-Product-1.7\"><span class=\"toc-item-num\">1.7&nbsp;&nbsp;</span>Cross Product</a></span></li><li><span><a href=\"#Intuition-behind-bross-and-dot-product\" data-toc-modified-id=\"Intuition-behind-bross-and-dot-product-1.8\"><span class=\"toc-item-num\">1.8&nbsp;&nbsp;</span>Intuition behind bross and dot product</a></span></li></ul></li><li><span><a href=\"#Matrices-for-solving-system-by-elimination\" data-toc-modified-id=\"Matrices-for-solving-system-by-elimination-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Matrices for solving system by elimination</a></span><ul class=\"toc-item\"><li><span><a href=\"#Reduced-Row-echelon-form\" data-toc-modified-id=\"Reduced-Row-echelon-form-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Reduced Row echelon form</a></span></li></ul></li><li><span><a href=\"#Unit:-Matrix-transformations\" data-toc-modified-id=\"Unit:-Matrix-transformations-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Unit: Matrix transformations</a></span><ul class=\"toc-item\"><li><span><a href=\"#Functions-and-Linear-transformation\" data-toc-modified-id=\"Functions-and-Linear-transformation-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Functions and Linear transformation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Vector-Transformation\" data-toc-modified-id=\"Vector-Transformation-3.1.1\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span>Vector Transformation</a></span></li><li><span><a href=\"#Linear-Transformation\" data-toc-modified-id=\"Linear-Transformation-3.1.2\"><span class=\"toc-item-num\">3.1.2&nbsp;&nbsp;</span>Linear Transformation</a></span></li></ul></li><li><span><a href=\"#Matrix-vector-products-as-linear-transformations\" data-toc-modified-id=\"Matrix-vector-products-as-linear-transformations-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Matrix vector products as linear transformations</a></span></li></ul></li><li><span><a href=\"#Matrix-Transformation\" data-toc-modified-id=\"Matrix-Transformation-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Matrix Transformation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Finding-inverse-and-determinants\" data-toc-modified-id=\"Finding-inverse-and-determinants-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Finding inverse and determinants</a></span><ul class=\"toc-item\"><li><span><a href=\"#3-x-3-determinant\" data-toc-modified-id=\"3-x-3-determinant-4.1.1\"><span class=\"toc-item-num\">4.1.1&nbsp;&nbsp;</span>3 x 3 determinant</a></span></li></ul></li><li><span><a href=\"#Transpose-of-a-matrix\" data-toc-modified-id=\"Transpose-of-a-matrix-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Transpose of a matrix</a></span><ul class=\"toc-item\"><li><span><a href=\"#Determinant-of-a-transpose\" data-toc-modified-id=\"Determinant-of-a-transpose-4.2.1\"><span class=\"toc-item-num\">4.2.1&nbsp;&nbsp;</span>Determinant of a transpose</a></span></li><li><span><a href=\"#Transpose-of-a-matrix-product\" data-toc-modified-id=\"Transpose-of-a-matrix-product-4.2.2\"><span class=\"toc-item-num\">4.2.2&nbsp;&nbsp;</span>Transpose of a matrix product</a></span></li></ul></li><li><span><a href=\"#Transpose-of-sums-and-inverses\" data-toc-modified-id=\"Transpose-of-sums-and-inverses-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Transpose of sums and inverses</a></span><ul class=\"toc-item\"><li><span><a href=\"#Transpose-of-a--vector\" data-toc-modified-id=\"Transpose-of-a--vector-4.3.1\"><span class=\"toc-item-num\">4.3.1&nbsp;&nbsp;</span>Transpose of a  vector</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector dot and cross products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Dot product:\n",
    "    - Multiplication of 2 vectors. Gives Scalar\n",
    "    \n",
    "## Vector Length:\n",
    "    - Sq root of sum of squares of individual components\n",
    "    \n",
    "<img src = './Images/VDC-1.png' width = 500 align = \"center\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Dot Product Rules:\n",
    "\n",
    "1. v*w = w*v\n",
    "2. (v+w)* x = (v * x + w * x)\n",
    "\n",
    "<img src = './Images/VDC-2.png' width = 500 align = \"center\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cauchy-Schwarz inequality\n",
    "\n",
    "<img src = './Images/VDC-3.png' width = 500 align = \"center\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Triangle Inequality\n",
    "\n",
    "<img src = './Images/VDC-4.png' width = 500 align = \"center\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Angle b/w 2 vectors.\n",
    "\n",
    "- 2 perpendicular vector's dot product is 0. Conversely, if dot product of 2 vectors is 0, and both are non zero vectors, then they are perpendicular. They are also called Orthogonal vectors.\n",
    "\n",
    "<img src = './Images/VDC-5.png' width = 500 align = \"center\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Product\n",
    "- Different from dot product which gives a scalar, cross product of 2 vectors returns another vector which is orthogonal to the 2.\n",
    "- Notice the middle term below is opposite of the way the other 2 are calcd\n",
    "\n",
    "<img src = './Images/VDC-6.png' width = 500 align = \"center\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Also, orthogonal vector's dot product is 0. \n",
    "- So if a,b are orthogonal then a . b = 0\n",
    "- In this case, the vector:\n",
    "    > (a X b) . a = 0 OR\n",
    "    \n",
    "    > (a X b) . b = 0\n",
    "    \n",
    "<img src = './Images/VDC-7.png' width = 500 align = \"center\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = './Images/VDC-8.png' width = 500 align = \"center\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intuition behind bross and dot product\n",
    "[Link](https://www.khanacademy.org/math/linear-algebra/vectors-and-spaces/dot-cross-products/v/dot-and-cross-product-comparison-intuition)\n",
    "\n",
    "<img src = './Images/VDC-9.png' width = 500 align = \"center\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- to develop intuition of cross and dot product, focus on the 2 equations.\n",
    "a.b = |a||b|cos(t)\n",
    "aXb = |a||b|sin(t)\n",
    "\n",
    "Here, (t) is theta or the angle.\n",
    "To develop intuition of sin, cos think of the shortcut:\n",
    "soh cah toa\n",
    "sin - oh - opposite/hypo\n",
    "cos - ah - adjacent/ hypo\n",
    "tan - oa - opposite/ adjacent\n",
    "\n",
    "\n",
    "Looking at the eqn for cross and dot product, it is clear that for dot product we need projection of a on b. So it measures the product of lengths of vectors in same direction. Hence, dot product of orthogonal vectors is 0, since projection of a on b will be 0.\n",
    "\n",
    "Conversely, cross product will measure the perpendicular distance of a on b. So collinear vectors have a product of 0 as there is no perpendicular distance b/w a and b."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrices for solving system by elimination\n",
    "\n",
    "## Reduced Row echelon form\n",
    "\n",
    "<img src = './Images/VDC-10.png' width = 500 align = \"center\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In the above image, A is original augmented matrix. This is derived from the equations of the top left corner.\n",
    "- Reduced row echelon form of A is achieved when:\n",
    "    - Leading entries of each row are 1.\n",
    "    - other entries in that column are 0\n",
    "    - Any zeroed out rows are last\n",
    "    - leading 1 of next row is to the right of previous one\n",
    "    \n",
    "- these 1s are called pivot entries,\n",
    "- shortform is ref(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit: Matrix transformations\n",
    "## Functions and Linear transformation\n",
    "\n",
    "### Vector Transformation\n",
    "\n",
    "\n",
    "\n",
    "<img src = './Images/VDC-11.png' width = 500 align = \"center\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- One of the term that is usually used in Linear algebra is Transformation which is essentially a function operation of vectors. The defintion of that function could be anything but think of transformation as another term for function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Transformation\n",
    "- Linear Transformation is true when the 2 conditions highlighted in pink are met.\n",
    "- A good cue is, linear transformations is when resulting members of transformations are due to some linear combinations. When we see multiplication/square/ etc, it is not a linear transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = './Images/VDC-12.png' width = 500 align = \"center\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix vector products as linear transformations\n",
    "- Matrix product with vectors is always a linear transformation.\n",
    "\n",
    "<img src = './Images/VDC-13.png' width = 500 align = \"center\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Transformation\n",
    "\n",
    "## Finding inverse and determinants\n",
    "\n",
    "### 3 x 3 determinant\n",
    "\n",
    "<img src = './Images/VDC-14.png' width = 500 align = \"center\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = './Images/VDC-15.png' width = 500 align = \"center\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transpose of a matrix\n",
    "### Determinant of a transpose\n",
    "\n",
    "<img src = './Images/VDC-16.png' width = 500 align = \"center\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transpose of a matrix product\n",
    "<img src = './Images/VDC-17.png' width = 500 align = \"center\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transpose of sums and inverses\n",
    "<img src = './Images/VDC-18.png' width = 500 align = \"center\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transpose of a  vector\n",
    "- Notice for that for the first eqn, LHS is dot product and RHS is not.\n",
    "- Similar for 2nd eq\n",
    "\n",
    "\n",
    "<img src = './Images/VDC-19.png' width = 500 align = \"center\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
