{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Selecting-columns-and-rows-efficiently\" data-toc-modified-id=\"Selecting-columns-and-rows-efficiently-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Selecting columns and rows efficiently</a></span><ul class=\"toc-item\"><li><span><a href=\"#Measuring-time-I\" data-toc-modified-id=\"Measuring-time-I-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Measuring time I</a></span></li><li><span><a href=\"#Measuring-time-II\" data-toc-modified-id=\"Measuring-time-II-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Measuring time II</a></span></li><li><span><a href=\"#Locate-rows:-.iloc[]-and-.loc[]\" data-toc-modified-id=\"Locate-rows:-.iloc[]-and-.loc[]-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Locate rows: .iloc[] and .loc[]</a></span></li><li><span><a href=\"#Column-selection:-.iloc[]-vs-by-name\" data-toc-modified-id=\"Column-selection:-.iloc[]-vs-by-name-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Column selection: .iloc[] vs by name</a></span></li><li><span><a href=\"#Select-random-rows\" data-toc-modified-id=\"Select-random-rows-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Select random rows</a></span></li><li><span><a href=\"#Random-column-selection\" data-toc-modified-id=\"Random-column-selection-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>Random column selection</a></span></li></ul></li><li><span><a href=\"#Replacing-values-in-a-DataFrame\" data-toc-modified-id=\"Replacing-values-in-a-DataFrame-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Replacing values in a DataFrame</a></span><ul class=\"toc-item\"><li><span><a href=\"#Replace-scalar-values-using-.replace()\" data-toc-modified-id=\"Replace-scalar-values-using-.replace()-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Replace scalar values using .replace()</a></span><ul class=\"toc-item\"><li><span><a href=\"#Replacing-scalar-values-I\" data-toc-modified-id=\"Replacing-scalar-values-I-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Replacing scalar values I</a></span></li><li><span><a href=\"#Replace-scalar-values-II\" data-toc-modified-id=\"Replace-scalar-values-II-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>Replace scalar values II</a></span></li></ul></li><li><span><a href=\"#Replace-values-using-lists\" data-toc-modified-id=\"Replace-values-using-lists-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Replace values using lists</a></span><ul class=\"toc-item\"><li><span><a href=\"#Replace-multiple-values-I\" data-toc-modified-id=\"Replace-multiple-values-I-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>Replace multiple values I</a></span></li><li><span><a href=\"#Replace-multiple-values-II\" data-toc-modified-id=\"Replace-multiple-values-II-2.2.2\"><span class=\"toc-item-num\">2.2.2&nbsp;&nbsp;</span>Replace multiple values II</a></span></li></ul></li><li><span><a href=\"#Replace-values-using-dictionaries\" data-toc-modified-id=\"Replace-values-using-dictionaries-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Replace values using dictionaries</a></span><ul class=\"toc-item\"><li><span><a href=\"#Replace-single-values-I\" data-toc-modified-id=\"Replace-single-values-I-2.3.1\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>Replace single values I</a></span></li><li><span><a href=\"#Replace-single-values-II\" data-toc-modified-id=\"Replace-single-values-II-2.3.2\"><span class=\"toc-item-num\">2.3.2&nbsp;&nbsp;</span>Replace single values II</a></span></li><li><span><a href=\"#Replace-multiple-values-III\" data-toc-modified-id=\"Replace-multiple-values-III-2.3.3\"><span class=\"toc-item-num\">2.3.3&nbsp;&nbsp;</span>Replace multiple values III</a></span></li></ul></li></ul></li><li><span><a href=\"#Efficient-iterating\" data-toc-modified-id=\"Efficient-iterating-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Efficient iterating</a></span><ul class=\"toc-item\"><li><span><a href=\"#Looping-using-the-.iterrows()-function\" data-toc-modified-id=\"Looping-using-the-.iterrows()-function-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Looping using the .iterrows() function</a></span><ul class=\"toc-item\"><li><span><a href=\"#Create-a-generator-for-a-pandas-DataFrame\" data-toc-modified-id=\"Create-a-generator-for-a-pandas-DataFrame-3.1.1\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span>Create a generator for a pandas DataFrame</a></span></li><li><span><a href=\"#The-iterrows()-function-for-looping\" data-toc-modified-id=\"The-iterrows()-function-for-looping-3.1.2\"><span class=\"toc-item-num\">3.1.2&nbsp;&nbsp;</span>The iterrows() function for looping</a></span></li></ul></li><li><span><a href=\"#Looping-using-the-.apply()-function\" data-toc-modified-id=\"Looping-using-the-.apply()-function-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Looping using the .apply() function</a></span><ul class=\"toc-item\"><li><span><a href=\"#.apply()-for-rows-iteration\" data-toc-modified-id=\".apply()-for-rows-iteration-3.2.1\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>.apply() for rows iteration</a></span></li></ul></li><li><span><a href=\"#Vectorization-over-pandas-series\" data-toc-modified-id=\"Vectorization-over-pandas-series-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Vectorization over pandas series</a></span><ul class=\"toc-item\"><li><span><a href=\"#Vectorization-with-NumPy-arrays-using-.values()\" data-toc-modified-id=\"Vectorization-with-NumPy-arrays-using-.values()-3.3.1\"><span class=\"toc-item-num\">3.3.1&nbsp;&nbsp;</span>Vectorization with NumPy arrays using .values()</a></span></li></ul></li></ul></li><li><span><a href=\"#Data-manipulation-using-.groupby()\" data-toc-modified-id=\"Data-manipulation-using-.groupby()-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Data manipulation using .groupby()</a></span><ul class=\"toc-item\"><li><span><a href=\"#Data-transformation-using-.groupby().transform\" data-toc-modified-id=\"Data-transformation-using-.groupby().transform-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Data transformation using .groupby().transform</a></span><ul class=\"toc-item\"><li><span><a href=\"#The-min-max-normalization-using-.transform()\" data-toc-modified-id=\"The-min-max-normalization-using-.transform()-4.1.1\"><span class=\"toc-item-num\">4.1.1&nbsp;&nbsp;</span>The min-max normalization using .transform()</a></span></li><li><span><a href=\"#Transforming-values-to-probabilities\" data-toc-modified-id=\"Transforming-values-to-probabilities-4.1.2\"><span class=\"toc-item-num\">4.1.2&nbsp;&nbsp;</span>Transforming values to probabilities</a></span></li><li><span><a href=\"#Validation-of-normalization\" data-toc-modified-id=\"Validation-of-normalization-4.1.3\"><span class=\"toc-item-num\">4.1.3&nbsp;&nbsp;</span>Validation of normalization</a></span></li></ul></li><li><span><a href=\"#Data-filtration-using-the-filter()-function\" data-toc-modified-id=\"Data-filtration-using-the-filter()-function-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Data filtration using the filter() function</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "poker_hands = pd.read_csv('./Data/poker_hand.csv')\n",
    "baby = pd.read_csv('./Data/Popular_Baby_Names.csv')\n",
    "resturant = pd.read_csv('./Data/restaurant_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these value are missing in the provided dataset\n",
    "mapper = {0:'Nothing in hand',1:'One pair',2:'Two pairs',3:'Three of a kind',4:'Straight',5:'Flush',6:'Full house',7:'Four of a kind ',8:'Straight flush',9:'Royal flush'}\n",
    "\n",
    "# Adding explanation column\n",
    "poker_hands['Explanation'] = poker_hands['Class'].map(mapper)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting columns and rows efficiently"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring time I\n",
    "- In the lecture slides, you saw how the time.time() function can be loaded and used to assess the time required to perform a basic mathematical operation.\n",
    "\n",
    "- Now, you will use the same strategy to assess two different methods for solving a similar problem: calculate the sum of squares of all the positive integers from 1 to 1 million (1,000,000).\n",
    "\n",
    "- Similar to what you saw in the video, you will compare two methods; one that uses brute force and one more mathematically sophisticated.\n",
    "\n",
    "- In the function formula, we use the standard formula\n",
    "\n",
    "`Nâˆ—(N+1)(2N+1)6`\n",
    "\n",
    "where N=1,000,000.\n",
    "\n",
    "- In the function brute_force we loop over each number from 1 to 1 million and add it to the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function was originally preloaded in datacamp but was extracted using instructions here:\n",
    "# https://stackoverflow.com/questions/1562759/can-python-print-a-function-definition\n",
    "# import inspect\n",
    "# print(inspect.getsource(formula))\n",
    "\n",
    "def formula(N):\n",
    "    return N*(N+1)*(2*N+1)/6\n",
    "\n",
    "def brute_force(N):\n",
    "    res = 0\n",
    "    UL = N+1\n",
    "    for i in range(1,UL):\n",
    "        res+=i^2\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time using formula: 7.772445678710938e-05 sec\n",
      "Time using the brute force: 0.11705136299133301 sec\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Calculate the result of the problem using formula() and print the time required\n",
    "N = 1000000\n",
    "fm_start_time = time.time()\n",
    "first_method = formula(N)\n",
    "print(\"Time using formula: {} sec\".format(time.time() - fm_start_time))\n",
    "\n",
    "# Calculate the result of the problem using brute_force() and print the time required\n",
    "sm_start_time = time.time()\n",
    "second_method = brute_force(N)\n",
    "print(\"Time using the brute force: {} sec\".format(time.time() - sm_start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring time II\n",
    "- As we discussed in the lectures, in the majority of cases, a list comprehension is faster than a for loop.\n",
    "\n",
    "- In this demonstration, you will see a case where a list comprehension and a for loop have so small difference in efficiency that choosing either method will perform this simple task instantly.\n",
    "\n",
    "- In the list words, there are random words downloaded from the Internet. We are interested to create another list called listlet in which we only keep the words that start with the letter b.\n",
    "\n",
    "- In case you are not familiar with dealing with strings in Python, each string has the `.startswith()` attribute, which returns a True/False statement whether the string starts with a specific letter/phrase or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['a', 'AAA', 'AAAS', 'aardvark', 'Aarhus', 'Aaron', 'ABA', 'Ababa', 'aback', 'abacus', 'abalone', 'abandon', 'abase', 'abash', 'abate', 'abbas', 'abbe', 'abbey', 'abbot', 'Abbott', 'abbreviate', 'abc', 'abdicate', 'abdomen', 'abdominal', 'abduct', 'Abe', 'abed', 'Abel', 'Abelian', 'Abelson', 'Aberdeen', 'Abernathy', 'aberrant', 'aberrate', 'abet', 'abetted', 'abetting', 'abeyance', 'abeyant', 'abhor', 'abhorred', 'abhorrent', 'abide', 'Abidjan', 'Abigail', 'abject', 'abjure', 'ablate', 'ablaze', 'able', 'ablution', 'abnegation', 'Abner', 'abnormal', 'Abo', 'aboard', 'abode', 'abolish', 'abolition', 'abominable', 'abominate', 'aboriginal', 'aborigine', 'aborning', 'abort', 'abound', 'about', 'above', 'aboveboard', 'aboveground', 'abovementioned', 'abrade', 'Abraham', 'Abram', 'Abramson', 'abrasion', 'abrasive', 'abreact', 'abreast', 'abridge', 'abridgment', 'abroad', 'abrogate', 'abrupt', 'abscess', 'abscissa', 'abscissae', 'abscond', 'absent', 'absentee', 'absenteeism', 'absentia', 'absentminded', 'absinthe', 'absolute', 'absolution', 'absolve', 'absorb', 'absorbent', 'absorption', 'absorptive', 'abstain', 'abstention', 'abstinent', 'abstract', 'abstractor', 'abstruse', 'absurd', 'absurdum', 'abuilding', 'abundant', 'abusable', 'abuse', 'abusive', 'abut', 'abutted', 'abutting', 'abysmal', 'abyss', 'Abyssinia', 'AC', 'acacia', 'academia', 'academic', 'academician', 'academy', 'Acadia', 'acanthus', 'Acapulco', 'accede', 'accelerate', 'accelerometer', 'accent', 'accentual', 'accentuate', 'accept', 'acceptant', 'acceptor', 'access', 'accessible', 'accession', 'accessory', 'accident', 'accidental', 'accipiter', 'acclaim', 'acclamation', 'acclimate', 'accolade', 'accommodate', 'accompaniment', 'accompanist', 'accompany', 'accomplice', 'accomplish', 'accord', 'accordant', 'accordion', 'accost', 'account', 'accountant', 'accouter', 'Accra', 'accredit', 'accreditation', 'accretion', 'accrual', 'accrue', 'acculturate', 'accumulate', 'accuracy', 'accurate', 'accusation', 'accusative', 'accusatory', 'accuse', 'accustom', 'ace', 'acerbic', 'acerbity', 'acetaminophen', 'acetate', 'acetic', 'acetone', 'acetylene', 'Achaean', 'ache', 'achieve', 'Achilles', 'aching', 'achromatic', 'acid', 'acidic', 'acidify', 'acidulate', 'acidulous', 'Ackerman', 'Ackley', 'acknowledge', 'acknowledgeable', 'ACM', 'acme', 'acolyte', 'acorn', 'acoustic', 'acquaint', 'acquaintance', 'acquiesce', 'acquiescent', 'acquire', 'acquisition', 'acquisitive', 'acquit', 'acquittal', 'acquitting', 'acre', 'acreage', 'acrid', 'acrimonious', 'acrimony', 'acrobacy', 'acrobat', 'acrobatic', 'acronym', 'acrophobia', 'acrophobic', 'acropolis', 'across', 'acrylate', 'acrylic', 'act', 'Actaeon', 'actinic', 'actinide', 'actinium', 'actinolite', 'actinometer', 'activate', 'Acton', 'actor', 'actress', 'actual', 'actuarial', 'actuate', 'acuity', 'acumen', 'acupuncture', 'acute', 'acyclic', 'ad', 'Ada', 'adage', 'adagio', 'Adair', 'Adam', 'adamant', 'Adamson', 'adapt', 'adaptation', 'adaptive', 'add', 'addend', 'addenda', 'addendum', 'addict', 'Addis', 'Addison', 'addition', 'additive', 'addle', 'address', 'addressee', 'Addressograph', 'adduce', 'Adelaide', 'Adele', 'Adelia', 'Aden', 'adenine', 'adenoma', 'adenosine', 'adept', 'adequacy', 'adequate', 'adhere', 'adherent', 'adhesion', 'adhesive', 'adiabatic', 'adieu', 'adipic', 'Adirondack', 'adjacent', 'adject', 'adjectival', 'adjoin', 'adjoint', 'adjourn', 'adjudge', 'adjudicate', 'adjunct', 'adjust', 'adjutant', 'Adkins', 'Adler', 'Adlerian', 'administer', 'administrable', 'administrate', 'administratrix', 'admiral', 'admiralty', 'admiration', 'admire', 'admissible', 'admission', 'admit', 'admittance', 'admitted', 'admitting', 'admix', 'admixture', 'admonish', 'admonition', 'ado', 'adobe', 'adolescent', 'Adolph', 'Adolphus', 'Adonis', 'adopt', 'adoption', 'adoptive', 'adoration', 'adore', 'adorn', 'adposition', 'adrenal', 'adrenalin', 'adrenaline', 'Adrian', 'Adriatic', 'Adrienne', 'adrift', 'adroit', 'adsorb', 'adsorbate', 'adsorption', 'adsorptive', 'adulate', 'adult', 'adulterate', 'adulterous', 'adultery', 'advance', 'advantage', 'advantageous', 'advent', 'adventitious', 'adventure', 'adventurous', 'adverb', 'adverbial', 'adversary', 'adverse', 'advert', 'advertise', 'advice', 'advisable', 'advise', 'advisee', 'advisor', 'advisory', 'advocacy', 'advocate', 'Aegean', 'aegis', 'Aeneas', 'Aeneid', 'aeolian', 'Aeolus', 'aerate', 'aerial', 'aerie', 'Aerobacter', 'aerobic', 'aerodynamic', 'aerofoil', 'aerogene', 'aeronautic', 'aerosol', 'aerospace', 'Aeschylus', 'Aesop', 'aesthete', 'aesthetic', 'afar', 'affable', 'affair', 'affect', 'affectate', 'affectionate', 'afferent', 'affiance', 'affidavit', 'affiliate', 'affine', 'affirm', 'affirmation', 'affirmative', 'affix', 'afflict', 'affluent', 'afford', 'afforest', 'afforestation', 'affricate', 'affront', 'Afghan', 'Afghanistan', 'aficionado', 'afield', 'afire', 'aflame', 'afloat', 'afoot', 'aforementioned', 'aforesaid', 'aforethought', 'afraid', 'afreet', 'afresh', 'Africa', 'Afrikaans', 'Afrikaner', 'afro', 'aft', 'afterbirth', 'aftereffect', 'afterglow', 'afterimage', 'afterlife', 'aftermath', 'afternoon', 'afterthought', 'afterward', 'afterword', 'again', 'against', 'Agamemnon', 'agar', 'agate', 'Agatha', 'agave', 'age', 'Agee', 'agenda', 'agent', 'agglomerate', 'agglutinate', 'agglutinin', 'aggravate', 'aggregate', 'aggression', 'aggressive', 'aggressor', 'aggrieve', 'aghast', 'agile', 'agitate', 'agleam', 'Agnes', 'Agnew', 'agnomen', 'agnostic', 'ago', 'agog', 'agone', 'agony', 'agouti', 'agrarian', 'agree', 'agreeable', 'agreeing', 'agribusiness', 'Agricola', 'agricultural', 'agriculture', 'agrimony', 'agronomist', 'agronomy', 'ague', 'Agway', 'ah', 'ahead', 'ahem', 'Ahmedabad', 'ahoy', 'aid', 'Aida', 'aide', 'Aides', 'Aiken', 'ail', 'ailanthus', 'aile', 'aileron', 'aim', \"ain't\", 'Ainu', 'air', 'airborne', 'airbrush', 'aircraft', 'airdrop', 'airedale', 'Aires', 'airfare', 'airfield', 'airflow', 'airframe', 'airlift', 'airline', 'airlock', 'airmail', 'airman', 'airmass', 'airmen', 'airpark', 'airplane', 'airport', 'airspeed', 'airstrip', 'airtight', 'airway', 'airy', 'aisle', 'Aitken', 'ajar', 'Ajax', 'AK', 'Akers', 'akin', 'Akron', 'AL', 'ala', 'Alabama', 'Alabamian', 'alabaster', 'alacrity', 'Aladdin', 'alai', 'Alameda', 'Alamo', 'alan', 'alarm', 'Alasdair', 'Alaska', 'Alastair', 'alb', 'alba', 'albacore', 'Albania', 'Albany', 'albatross', 'albeit', 'Alberich', 'Albert', 'Alberta', 'Alberto', 'albino', 'Albrecht', 'Albright', 'album', 'albumin', 'Albuquerque', 'Alcestis', 'alchemist', 'alchemy', 'Alcmena', 'Alcoa', 'alcohol', 'alcoholic', 'Alcott', 'alcove', 'Aldebaran', 'aldehyde', 'Alden', 'alder', 'alderman', 'aldermen', 'Aldrich', 'aldrin', 'ale', 'Alec', 'Aleck', 'aleph', 'alert', 'Aleutian', 'alewife', 'Alex', 'Alexander', 'Alexandra', 'Alexandre', 'Alexandria', 'Alexei', 'Alexis', 'alfalfa', 'alfonso', 'Alfred', 'Alfredo', 'alfresco', 'alga', 'algae', 'algaecide', 'algal', 'algebra', 'algebraic', 'Algenib', 'Alger', 'Algeria', 'Algiers', 'alginate', 'Algol', 'Algonquian', 'Algonquin', 'algorithm', 'algorithmic', 'Alhambra', 'Ali', 'alia', 'alias', 'alibi', 'Alice', 'Alicia', 'alien', 'alienate', 'alight', 'align', 'alike', 'alimentary', 'alimony', 'aliphatic', 'aliquot', 'Alison', 'Alistair', 'alive', 'alizarin', 'alkali', 'alkaline', 'alkaloid', 'all', 'Allah', 'Allan', 'allay', 'allegate', 'allege', 'Allegheny', 'allegiant', 'allegoric', 'allegory', 'Allegra', 'allegro', 'allele', 'allemand', 'Allen', 'Allentown', 'allergic', 'allergy', 'alleviate', 'alley', 'alleyway', 'alliance', 'alligator', 'Allis', 'Allison', 'alliterate', 'allmsgs', 'allocable', 'allocate', 'allot', 'allotropic', 'allotted', 'allotting', 'allow', 'allowance', 'alloy', 'allspice', 'Allstate', 'allude', 'allure', 'allusion', 'allusive', 'alluvial', 'alluvium', 'ally', 'allyl', 'Allyn', 'alma', 'Almaden', 'almagest', 'almanac', 'almighty', 'almond', 'almost', 'aloe', 'aloft', 'aloha', 'alone', 'along', 'alongside', 'aloof', 'aloud', 'alp', 'alpaca', 'alpenstock', 'Alpert', 'alpha', 'alphabet', 'alphabetic', 'alphanumeric', 'Alpheratz', 'Alphonse', 'alpine', 'already', 'Alsatian', 'also', 'Alsop', 'Altair', 'altar', 'alter', 'alterate', 'altercate', 'altern', 'alternate', 'althea', 'although', 'altimeter', 'altitude', 'alto', 'altogether', 'Alton', 'altruism', 'altruist', 'alum', 'alumina', 'aluminate', 'alumna', 'alumnae', 'alumni', 'alumnus', 'alundum', 'Alva', 'Alvarez', 'alveolar', 'alveoli', 'alveolus', 'Alvin', 'always', 'alyssum', 'A&M', 'am', 'AMA', 'Amadeus', 'amalgam', 'amalgamate', 'amanita', 'amanuensis', 'amaranth', 'Amarillo', 'amass', 'amateur', 'amateurish', 'amatory', 'amaze', 'Amazon', 'ambassador', 'amber', 'ambiance', 'ambidextrous', 'ambient', 'ambiguity', 'ambiguous', 'ambition', 'ambitious', 'ambivalent', 'amble', 'ambrose', 'ambrosia', 'ambrosial', 'ambulant', 'ambulatory', 'ambuscade', 'ambush', 'Amelia', 'ameliorate', 'amen', 'amend', 'amende', 'Amerada', 'America', 'Americana', 'americium', 'Ames', 'amethyst', 'amethystine', 'Amharic', 'Amherst', 'ami', 'amicable', 'amid', 'amide', 'amidst', 'amigo', 'amino', 'aminobenzoic', 'amiss', 'amity', 'Amman', 'Ammerman', 'ammeter', 'ammo', 'ammonia', 'ammoniac', 'ammonite', 'ammonium', 'ammunition', 'amnesia', 'amnesiac', 'amnesty', 'amniocentesis', 'amniotic', 'Amoco', 'amoeba', 'amoebae', 'amoeboid', 'amok', 'among', 'amongst', 'amoral', 'amorphous', 'amort', 'Amos', 'amount', 'amp', 'amperage', 'ampere', 'ampersand', 'Ampex', 'amphetamine', 'amphibian', 'amphibious', 'amphibole', 'amphibology', 'amphioxis', 'ample', 'amplify', 'amplitude', 'amply', 'amputate', 'amra', 'Amsterdam', 'Amtrak', 'amulet', 'amuse', 'amy', 'amygdaloid', 'an', 'ana', 'Anabaptist', 'Anabel', 'anachronism', 'anachronistic', 'anaconda', 'Anacreon', 'anaerobic', 'anaglyph', 'anagram', 'Anaheim', 'Analects', 'analeptic', 'analgesic', 'analogous', 'analogue', 'analogy', 'analyses', 'analysis', 'analyst', 'analytic', 'anamorphic', 'anaphora', 'anaphoric', 'anaplasmosis', 'anarch', 'anarchic', 'anarchy', 'Anastasia', 'anastigmat', 'anastigmatic', 'anastomosis', 'anastomotic', 'anathema', 'Anatole', 'anatomic', 'anatomist', 'anatomy', 'ancestor', 'ancestral', 'ancestry', 'anchor', 'anchorage', 'anchorite', 'anchovy', 'ancient', 'ancillary', 'and', 'Andalusia', 'Andean', 'Andersen', 'Anderson', 'Andes', 'andesine', 'andesite', 'Andorra', 'Andover', 'Andre', 'Andrea', 'Andrei', 'Andrew', 'androgen', 'Andromache', 'Andromeda', 'Andy', 'anecdotal', 'anecdote', 'anemone', 'anent', 'anew', 'angel', 'Angela', 'Angeles', 'angelfish', 'angelic', 'Angelica', 'Angelina', 'Angeline', 'Angelo', 'anger', 'Angie', 'angiosperm', 'angle', 'Angles', 'Anglican', 'Anglo', 'Anglophobia', 'Angola', 'Angora', 'angry', 'angst', 'angstrom', 'anguish', 'angular', 'Angus', 'anharmonic', 'Anheuser', 'anhydride', 'anhydrite', 'anhydrous', 'ani', 'aniline', 'animadversion', 'animadvert', 'animal', 'animate', 'animism', 'animist', 'animosity', 'anion', 'anionic', 'anise', 'aniseikonic', 'anisotropic', 'anisotropy', 'Anita', 'Ankara', 'ankle', 'Ann', 'Anna', 'annal', 'Annale', 'Annalen', 'Annapolis', 'Anne', 'anneal', 'annelid', 'Annette', 'annex', 'Annie', 'annihilate']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time using list comprehension: 0.00024771690368652344 sec\n",
      "Time using for loop: 0.00026988983154296875 sec\n"
     ]
    }
   ],
   "source": [
    "# Store the time before the execution\n",
    "start_time = time.time()\n",
    "\n",
    "# Execute the operation\n",
    "letlist = [wrd for wrd in words if wrd.startswith('b')]\n",
    "\n",
    "# Store and print the difference between the start and the current time\n",
    "total_time_lc = time.time() - start_time\n",
    "print('Time using list comprehension: {} sec'.format(total_time_lc))\n",
    "\n",
    "# Store the time before the execution\n",
    "start_time = time.time()\n",
    "\n",
    "# Execute the operation\n",
    "letlist = []\n",
    "for wrd in words:\n",
    "    if wrd.startswith('b'):\n",
    "        letlist.append(wrd)\n",
    "        \n",
    "# Print the difference between the start and the current time\n",
    "total_time_fl = time.time() - start_time\n",
    "print('Time using for loop: {} sec'.format(total_time_fl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Locate rows: .iloc[] and .loc[]\n",
    "\n",
    "- A big part of working with DataFrames is to locate specific entries in the dataset. You can locate rows in two ways:\n",
    "\n",
    "    - By a specific value of a column (feature).\n",
    "    - By the index of the rows (index). In this exercise, we will focus on the second way.\n",
    "\n",
    "- If you have previous experience with pandas, you should be familiar with the .loc and .iloc indexers, which stands for 'location' and 'index location' respectively. In most cases, the indices will be the same as the position of each row in the Dataframe (e.g. the row with index 13 will be the 14th entry)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time using .loc[]: 0.002582073211669922 sec\n",
      "Time using .iloc[]: 0.0010418891906738281 sec\n"
     ]
    }
   ],
   "source": [
    "# Define the range of rows to select: row_nums\n",
    "row_nums = range(0, 1000)\n",
    "\n",
    "# Select the rows using .loc[] and row_nums and record the time before and after\n",
    "loc_start_time = time.time()\n",
    "rows = poker_hands.loc[row_nums]\n",
    "loc_end_time = time.time()\n",
    "\n",
    "# Print the time it took to select the rows using .loc\n",
    "print(\"Time using .loc[]: {} sec\".format(loc_end_time - loc_start_time))\n",
    "\n",
    "# Select the rows using .iloc[] and row_nums and record the time before and after\n",
    "iloc_start_time = time.time()\n",
    "rows = poker_hands.iloc[row_nums]\n",
    "iloc_end_time = time.time()\n",
    "\n",
    "# Print the time it took to select the rows using .iloc\n",
    "print(\"Time using .iloc[]: {} sec\".format(iloc_end_time-iloc_start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- iloc does better: There is an explanation for that, .iloc() takes advantages of the sorted position of each rows, simplifying the computations needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column selection: .iloc[] vs by name\n",
    "\n",
    "- In the previous exercise, you saw how the .loc[] and .iloc[] functions can be used to locate specific rows of a DataFrame (based on the index). Turns out, the .iloc[] function performs a lot faster (~ 2 times) for this task!\n",
    "\n",
    "- Another important task is to find the faster function to select the targeted features (columns) of a DataFrame. In this exercise, we will compare the following:\n",
    "\n",
    "    - using the index locator .iloc()\n",
    "    - using the names of the columns While we can use both functions to perform the same task, we are interested in which is the most efficient in terms of speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time using .iloc[] : 0.0006010532379150391 sec\n",
      "Time using selection by name : 0.0053691864013671875 sec\n"
     ]
    }
   ],
   "source": [
    "# Use .iloc to select the first 6 columns and record the times before and after\n",
    "iloc_start_time = time.time()\n",
    "cols = poker_hands.iloc[:,0:6]\n",
    "iloc_end_time = time.time()\n",
    "\n",
    "# Print the time it took\n",
    "print(\"Time using .iloc[] : {} sec\".format(iloc_end_time - iloc_start_time))\n",
    "\n",
    "# Use simple column selection to select the first 6 columns \n",
    "names_start_time = time.time()\n",
    "cols = poker_hands[['S1', 'R1', 'S2', 'R2', 'S3', 'R3']]\n",
    "names_end_time = time.time()\n",
    "\n",
    "# Print the time it took\n",
    "print(\"Time using selection by name : {} sec\".format(names_end_time-names_start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now, in theory, selection by name should have been quicker but clearly isn't here.\n",
    "- The reason selection by name would have been quicker is because iloc needs both rows and columns needed which takes more time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select random rows\n",
    "\n",
    "- In this exercise, you will compare the two methods described for selecting random rows (entries) with replacement in a pandas DataFrame:\n",
    "\n",
    "    - The built-in pandas function .random()\n",
    "    - The NumPy random integer number generator np.random.randint()\n",
    "\n",
    "- Generally, in the fields of statistics and machine learning, when we need to train an algorithm, we train the algorithm on the 75% of the available data and then test the performance on the remaining 25% of the data.\n",
    "\n",
    "- For this exercise, we will randomly sample the 75% percent of all the played poker hands available, using each of the above methods, and check which method is more efficient in terms of speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time using Numpy: 0.005445957183837891 sec\n",
      "Time using .sample: 0.002415895462036133 sec\n"
     ]
    }
   ],
   "source": [
    "# Extract number of rows in dataset\n",
    "N=poker_hands.shape[0]\n",
    "\n",
    "# Select and time the selection of the 75% of the dataset's rows\n",
    "rand_start_time = time.time()\n",
    "poker_hands.iloc[np.random.randint(low=0, high=N, size=int(0.75 * N))]\n",
    "print(\"Time using Numpy: {} sec\".format(time.time() - rand_start_time))\n",
    "\n",
    "# Select and time the selection of the 75% of the dataset's rows using sample()\n",
    "samp_start_time = time.time()\n",
    "poker_hands.sample(int(0.75 * N), axis=0, replace = True)\n",
    "print(\"Time using .sample: {} sec\".format(time.time() - samp_start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random column selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time using NymPy's random.randint(): 0.0015060901641845703 sec\n",
      "Time using panda's .sample(): 0.0013928413391113281 sec\n"
     ]
    }
   ],
   "source": [
    "# Extract number of columns in dataset\n",
    "D=poker_hands.shape[1]\n",
    "\n",
    "# Select and time the selection of 4 of the dataset's columns using NumPy\n",
    "np_start_time = time.time()\n",
    "poker_hands.iloc[:,np.random.randint(low=0, high=D, size=4)]\n",
    "print(\"Time using NymPy's random.randint(): {} sec\".format(time.time() - np_start_time))\n",
    "\n",
    "# Select and time the selection of 4 of the dataset's columns using pandas\n",
    "pd_start_time = time.time()\n",
    "poker_hands.sample(4, axis=1)\n",
    "print(\"Time using panda's .sample(): {} sec\".format(time.time() - pd_start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replacing values in a DataFrame\n",
    "\n",
    "## Replace scalar values using .replace()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing scalar values I\n",
    "- In this exercise, we will replace a list of values in our dataset by using the .replace() method with another list of desired values.\n",
    "\n",
    "- We will apply the functions in the poker_hands DataFrame. Remember that in the poker_hands DataFrame, each row of columns R1 to R5 represents the rank of each card from a player's poker hand spanning from 1 (Ace) to 13 (King). The Class feature classifies each hand as a category, and the Explanation feature briefly explains each hand.\n",
    "\n",
    "- The poker_hands DataFrame is already loaded for you, and you can explore the features Class and Explanation.\n",
    "\n",
    "- Remember you can always explore the dataset and see how it changes in the IPython Shell, and refer to the slides in the Slides tab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Class\n",
      "0          9\n",
      "1          9\n",
      "2          9\n",
      "3          9\n",
      "4          9\n",
      "...      ...\n",
      "25005      0\n",
      "25006      1\n",
      "25007      1\n",
      "25008      1\n",
      "25009      1\n",
      "\n",
      "[25010 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Replace Class 1 to -2 \n",
    "poker_hands['Class'].replace(1, -2, inplace=False)\n",
    "# Replace Class 2 to -3\n",
    "poker_hands['Class'].replace(2, -3, inplace=False)\n",
    "\n",
    "print(poker_hands[['Class']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace scalar values II\n",
    "\n",
    "- As discussed in the video, in a pandas DataFrame, it is possible to replace values in a very intuitive way: we locate the position (row and column) in the Dataframe and assign in the new value you want to replace with. In a more pandas-ian way, the .replace() function is available that performs the same task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time using .loc[]: 0.005151987075805664 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:205: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "names = baby.copy()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Replace all the entries that has 'FEMALE' as a gender with 'GIRL'\n",
    "names['Gender'].loc[names['Gender'] == 'FEMALE'] = 'GIRL'\n",
    "\n",
    "print(\"Time using .loc[]: {} sec\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time using .replace(): 0.0016722679138183594 sec\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Replace all the entries that has 'FEMALE' as a gender with 'GIRL'\n",
    "names['Gender'].replace('FEMALE', 'GIRL', inplace=True)\n",
    "\n",
    "print(\"Time using .replace(): {} sec\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace values using lists\n",
    "\n",
    "### Replace multiple values I\n",
    "- In this exercise, you will apply the .replace() function for the task of replacing multiple values with one or more values. You will again use the names dataset which contains, among others, the most popular names in the US by year, gender and Ethnicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time using .loc[]: sec\n"
     ]
    }
   ],
   "source": [
    "names = baby.copy()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Replace all non-Hispanic ethnicities with 'NON HISPANIC'\n",
    "names['Ethnicity'].loc[(names[\"Ethnicity\"] == 'BLACK NON HISP') | \n",
    "                      (names[\"Ethnicity\"] == 'BLACK NON HISPANIC') | \n",
    "                      (names['Ethnicity'] == 'WHITE NON HISP') | \n",
    "                      (names['Ethnicity'] == 'WHITE NON HISPANIC')] = 'NON HISPANIC'\n",
    "\n",
    "print(\"Time using .loc[]: sec\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time using .replace(): 0.0017120838165283203 sec\n"
     ]
    }
   ],
   "source": [
    "names = baby.copy()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Replace all non-Hispanic ethnicities with 'NON HISPANIC'\n",
    "names['Ethnicity'].replace(['BLACK NON HISP', 'BLACK NON HISPANIC', 'WHITE NON HISP' , 'WHITE NON HISPANIC'], 'NON HISPANIC', inplace=True)\n",
    "\n",
    "print(\"Time using .replace(): {} sec\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace multiple values II\n",
    "\n",
    "- As discussed in the video, instead of using the .replace() function multiple times to replace multiple values, you can use lists to map the elements you want to replace one to one with those you want to replace them with.\n",
    "\n",
    "- As you have seen in our popular names dataset, there are two names for the same ethnicity. We want to standardize the naming of each ethnicity by replacing\n",
    "\n",
    "    - 'ASIAN AND PACI' to 'ASIAN AND PACIFIC ISLANDER'\n",
    "    - 'BLACK NON HISP' to 'BLACK NON HISPANIC'\n",
    "    - 'WHITE NON HISP' to 'WHITE NON HISPANIC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time using .replace(): 0.0013890266418457031 sec\n"
     ]
    }
   ],
   "source": [
    "names = baby.copy()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Replace ethnicities as instructed\n",
    "names['Ethnicity'].replace(['ASIAN AND PACI','BLACK NON HISP', 'WHITE NON HISP'], ['ASIAN AND PACIFIC ISLANDER','BLACK NON HISPANIC','WHITE NON HISPANIC'], inplace=True)\n",
    "\n",
    "print(\"Time using .replace(): {} sec\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace values using dictionaries\n",
    "\n",
    "\n",
    "### Replace single values I\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Flush\n",
      "1    Flush\n",
      "2    Flush\n",
      "3    Flush\n",
      "4    Flush\n",
      "Name: Explanation, dtype: object\n"
     ]
    }
   ],
   "source": [
    "poker_hands_copy = poker_hands.copy()\n",
    "\n",
    "# Replace Royal flush or Straight flush to Flush\n",
    "# Note that column is not specified.\n",
    "poker_hands_copy.replace({'Royal flush':'Flush', 'Straight flush':'Flush'}, inplace=True)\n",
    "\n",
    "print(poker_hands_copy['Explanation'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace single values II\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Year of Birth  Gender                   Ethnicity Child's First Name  \\\n",
      "0           2011  FEMALE  ASIAN AND PACIFIC ISLANDER             SOPHIA   \n",
      "1           2011  FEMALE  ASIAN AND PACIFIC ISLANDER              CHLOE   \n",
      "2           2011  FEMALE  ASIAN AND PACIFIC ISLANDER              EMILY   \n",
      "3           2011  FEMALE  ASIAN AND PACIFIC ISLANDER             OLIVIA   \n",
      "4           2011  FEMALE  ASIAN AND PACIFIC ISLANDER               EMMA   \n",
      "\n",
      "   Count  Rank  \n",
      "0    119     1  \n",
      "1    106     2  \n",
      "2     93     3  \n",
      "3     89     4  \n",
      "4     75     5   \n",
      "\n",
      "\n",
      "   Year of Birth  Gender                   Ethnicity Child's First Name  \\\n",
      "0           2011  FEMALE  ASIAN AND PACIFIC ISLANDER             SOPHIA   \n",
      "1           2011  FEMALE  ASIAN AND PACIFIC ISLANDER              CHLOE   \n",
      "2           2011  FEMALE  ASIAN AND PACIFIC ISLANDER              EMILY   \n",
      "3           2011  FEMALE  ASIAN AND PACIFIC ISLANDER             OLIVIA   \n",
      "4           2011  FEMALE  ASIAN AND PACIFIC ISLANDER               EMMA   \n",
      "\n",
      "   Count    Rank  \n",
      "0    119   FIRST  \n",
      "1    106  SECOND  \n",
      "2     93   THIRD  \n",
      "3     89       4  \n",
      "4     75       5  \n"
     ]
    }
   ],
   "source": [
    "# Copy the DF\n",
    "names_replace = names.head()\n",
    "print(names_replace,'\\n\\n')\n",
    "\n",
    "# Replace the number rank by a string\n",
    "# Note that column is specified, unlike earlier\n",
    "names_replace['Rank'].replace({1:'FIRST', 2:'SECOND', 3:'THIRD'}, inplace=True)\n",
    "print(names_replace.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace multiple values III\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Year of Birth  Gender                   Ethnicity Child's First Name  \\\n",
      "0           2011  FEMALE  ASIAN AND PACIFIC ISLANDER             SOPHIA   \n",
      "1           2011  FEMALE  ASIAN AND PACIFIC ISLANDER              CHLOE   \n",
      "2           2011  FEMALE  ASIAN AND PACIFIC ISLANDER              EMILY   \n",
      "3           2011  FEMALE  ASIAN AND PACIFIC ISLANDER             OLIVIA   \n",
      "4           2011  FEMALE  ASIAN AND PACIFIC ISLANDER               EMMA   \n",
      "\n",
      "   Count  Rank  \n",
      "0    119     1  \n",
      "1    106     2  \n",
      "2     93     3  \n",
      "3     89     4  \n",
      "4     75     5  \n",
      "   Year of Birth  Gender                   Ethnicity Child's First Name  \\\n",
      "0           2011  FEMALE  ASIAN AND PACIFIC ISLANDER             SOPHIA   \n",
      "1           2011  FEMALE  ASIAN AND PACIFIC ISLANDER              CHLOE   \n",
      "2           2011  FEMALE  ASIAN AND PACIFIC ISLANDER              EMILY   \n",
      "3           2011  FEMALE  ASIAN AND PACIFIC ISLANDER             OLIVIA   \n",
      "4           2011  FEMALE  ASIAN AND PACIFIC ISLANDER               EMMA   \n",
      "\n",
      "   Count          Rank  \n",
      "0    119         MEDAL  \n",
      "1    106         MEDAL  \n",
      "2     93         MEDAL  \n",
      "3     89  ALMOST MEDAL  \n",
      "4     75  ALMOST MEDAL  \n"
     ]
    }
   ],
   "source": [
    "names_copy = names.copy()\n",
    "print(names_copy.head())\n",
    "\n",
    "# Replace the rank of the first three ranked names to 'MEDAL'\n",
    "names_copy.replace({'Rank': {1:'MEDAL', 2:'MEDAL', 3:'MEDAL'}}, inplace=True)\n",
    "\n",
    "# Replace the rank of the 4th and 5th ranked names to 'ALMOST MEDAL'\n",
    "names_copy.replace({'Rank': {4:'ALMOST MEDAL', 5:'ALMOST MEDAL'}}, inplace=True)\n",
    "print(names_copy.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Efficient iterating\n",
    " \n",
    "## Looping using the .iterrows() function\n",
    "\n",
    "### Create a generator for a pandas DataFrame\n",
    "\n",
    "- you can easily create a generator out of a pandas DataFrame. Each time you iterate through it, it will yield two elements:\n",
    "\n",
    "    - the index of the respective row\n",
    "    - a pandas Series with all the elements of that row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, S1                       1\n",
      "R1                      10\n",
      "S2                       1\n",
      "R2                      11\n",
      "S3                       1\n",
      "R3                      13\n",
      "S4                       1\n",
      "R4                      12\n",
      "S5                       1\n",
      "R5                       1\n",
      "Class                    9\n",
      "Explanation    Royal flush\n",
      "Name: 0, dtype: object) (1, S1                       2\n",
      "R1                      11\n",
      "S2                       2\n",
      "R2                      13\n",
      "S3                       2\n",
      "R3                      10\n",
      "S4                       2\n",
      "R4                      12\n",
      "S5                       2\n",
      "R5                       1\n",
      "Class                    9\n",
      "Explanation    Royal flush\n",
      "Name: 1, dtype: object)\n"
     ]
    }
   ],
   "source": [
    "# Create a generator over the rows\n",
    "generator = poker_hands.iterrows()\n",
    "\n",
    "# Access the elements of the 2nd row\n",
    "first_element = next(generator)\n",
    "second_element = next(generator)\n",
    "print(first_element, second_element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The iterrows() function for looping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = poker_hands.iterrows()\n",
    "\n",
    "for index, values in data_generator:\n",
    "  \t# Check if index is odd\n",
    "    if index%2 == 1:\n",
    "      \t# Sum the ranks of all the cards\n",
    "        hand_sum = sum([values[1], values[3], values[5], values[7], values[9]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looping using the .apply() function\n",
    "\n",
    "\n",
    "- Apply doesn't have to be only for rows. Switching axis=0 will run it for columns as well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   S1   R1  S2   R2  S3   R3  S4   R4  S5   R5\n",
      "0   1  100   1  121   1  169   1  144   1    1\n",
      "1   4  121   4  169   4  100   4  144   4    1\n",
      "2   9  144   9  121   9  169   9  100   9    1\n",
      "3  16  100  16  121  16    1  16  169  16  144\n",
      "4  16    1  16  169  16  144  16  121  16  100\n"
     ]
    }
   ],
   "source": [
    "# Define the lambda transformation\n",
    "get_square = lambda x: x**2\n",
    "\n",
    "# Apply the transformation\n",
    "data_sum = poker_hands.iloc[:,:-2].apply(get_square)\n",
    "print(data_sum.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .apply() for rows iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R1    14.060473\n",
      "R2    14.189523\n",
      "R3    14.024270\n",
      "R4    14.040552\n",
      "R5    13.998851\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "get_variance = lambda x: np.var(x)\n",
    "\n",
    "# Apply the transformation\n",
    "data_tr = poker_hands[['R1', 'R2', 'R3', 'R4', 'R5']].apply(get_variance, axis=0)\n",
    "print(data_tr.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization over pandas series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time using pandas vectorization for rows: 0.0042269229888916016 sec\n",
      "0    9.4\n",
      "1    9.4\n",
      "2    9.4\n",
      "3    9.4\n",
      "4    9.4\n",
      "dtype: float64\n",
      "Time using pandas vectorization for columns: 0.0015757083892822266 sec\n",
      "R1    6.995242\n",
      "R2    7.014194\n",
      "R3    7.014154\n",
      "R4    6.942463\n",
      "R5    6.962735\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mean rank in each hand\n",
    "row_start_time = time.time()\n",
    "mean_r = poker_hands[['R1', 'R2', 'R3', 'R4', 'R5']].mean(axis=1)\n",
    "print(\"Time using pandas vectorization for rows: {} sec\".format(time.time() - row_start_time))\n",
    "print(mean_r.head())\n",
    "\n",
    "# Calculate the mean rank of each of the 5 card in all hands\n",
    "col_start_time = time.time()\n",
    "mean_c = poker_hands[['R1', 'R2', 'R3', 'R4', 'R5']].mean(axis=0)\n",
    "print(\"Time using pandas vectorization for columns: {} sec\".format(time.time() - col_start_time))\n",
    "print(mean_c.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization with NumPy arrays using .values()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time using pandas vectorization: 0.003256082534790039 sec\n",
      "0    23.3\n",
      "1    23.3\n",
      "2    23.3\n",
      "3    23.3\n",
      "4    23.3\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate the variance in each hand\n",
    "start_time = time.time()\n",
    "poker_var = poker_hands[['R1', 'R2', 'R3', 'R4', 'R5']].var(axis=1)\n",
    "print(\"Time using pandas vectorization: {} sec\".format(time.time() - start_time))\n",
    "print(poker_var.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time using NumPy vectorization: 0.004090785980224609 sec\n",
      "[23.3 23.3 23.3 23.3 23.3]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the variance in each hand\n",
    "start_time = time.time()\n",
    "poker_var = poker_hands[['R1', 'R2', 'R3', 'R4', 'R5']].values.var(axis=1, ddof=1)\n",
    "print(\"Time using NumPy vectorization: {} sec\".format(time.time() - start_time))\n",
    "print(poker_var[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In theory, vectorization with numpy is quicker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data manipulation using .groupby()\n",
    "\n",
    "## Data transformation using .groupby().transform\n",
    "\n",
    "### The min-max normalization using .transform()\n",
    "- A very common operation is the min-max normalization. It consists in rescaling our value of interest by deducting the minimum value and dividing the result by the difference between the maximum and the minimum value. For example, to rescale student's weight data spanning from 160 pounds to 200 pounds, you subtract 160 from each student's weight and divide the result by 40 (200 - 160).\n",
    "\n",
    "- You're going to define and apply the min-max normalization to all the numerical variables in the restaurant data. You will first group the entries by the time the meal took place (Lunch or Dinner) and then apply the normalization to each group separately.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   total_bill       tip  size\n",
      "0    0.291579  0.001111   0.2\n",
      "1    0.152283  0.073333   0.4\n",
      "2    0.375786  0.277778   0.4\n",
      "3    0.431713  0.256667   0.2\n",
      "4    0.450775  0.290000   0.6\n"
     ]
    }
   ],
   "source": [
    "restaurant_data = resturant.copy()\n",
    "\n",
    "# Define the min-max transformation\n",
    "min_max_tr = lambda x: (x - x.min()) / (x.max() - x.min())\n",
    "\n",
    "# Group the data according to the time\n",
    "restaurant_grouped = restaurant_data.groupby('time')\n",
    "\n",
    "# Apply the transformation\n",
    "restaurant_min_max_group = restaurant_grouped.transform(min_max_tr)\n",
    "print(restaurant_min_max_group.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming values to probabilities\n",
    "- In this exercise, we will apply a probability distribution function to a pandas DataFrame with group related parameters by transforming the tip variable to probabilities.\n",
    "\n",
    "- The transformation will be a exponential transformation. The exponential distribution is defined as\n",
    "\n",
    "`eâˆ’Î»âˆ—xâˆ—Î»`\n",
    "- where Î» (lambda) is the mean of the group that the observation x belongs to.\n",
    "\n",
    "- You're going to apply the exponential distribution transformation to the size of each table in the dataset, after grouping the data according to the time of the day the meal took place. Remember to use each group's mean for the value of Î».\n",
    "\n",
    "- In Python, you can use the exponential as np.exp() from the NumPy library and the mean value as .mean()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.135141\n",
      "1    0.017986\n",
      "2    0.000060\n",
      "3    0.000108\n",
      "4    0.000042\n",
      "Name: tip, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Define the exponential transformation\n",
    "exp_tr = lambda x: np.exp(-x.mean()*x) * x.mean()\n",
    "\n",
    "# Group the data according to the time\n",
    "restaurant_grouped = restaurant_data.groupby('time')\n",
    "\n",
    "# Apply the transformation\n",
    "restaurant_exp_group = restaurant_grouped['tip'].transform(exp_tr)\n",
    "print(restaurant_exp_group.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation of normalization\n",
    "For this exercise, we will perform a z-score normalization and verify that it was performed correctly.\n",
    "\n",
    "A distinct characteristic of normalized values is that they have a mean equal to zero and standard deviation equal to one.\n",
    "\n",
    "After you apply the normalization transformation, you can group again on the same variable, and then check the mean and the standard deviation of each group.\n",
    "\n",
    "You will apply the normalization transformation to every numeric variable in the poker_grouped dataset, which is the poker_hands dataset grouped by Class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        S1   R1   S2   R2   S3   R3   S4   R4   S5   R5\n",
      "Class                                                  \n",
      "0      0.0  0.0 -0.0 -0.0 -0.0 -0.0  0.0 -0.0 -0.0 -0.0\n",
      "1     -0.0 -0.0  0.0 -0.0  0.0  0.0  0.0  0.0 -0.0  0.0\n",
      "2     -0.0 -0.0 -0.0 -0.0 -0.0  0.0 -0.0  0.0  0.0  0.0\n",
      "3     -0.0  0.0  0.0 -0.0 -0.0 -0.0  0.0 -0.0  0.0 -0.0\n",
      "4      0.0 -0.0 -0.0 -0.0  0.0 -0.0 -0.0  0.0  0.0  0.0\n",
      "5     -0.0 -0.0 -0.0  0.0 -0.0  0.0 -0.0 -0.0 -0.0  0.0\n",
      "6     -0.0 -0.0 -0.0  0.0  0.0 -0.0  0.0  0.0 -0.0  0.0\n",
      "7      0.0 -0.0 -0.0  0.0 -0.0  0.0  0.0 -0.0 -0.0 -0.0\n",
      "8     -0.0  0.0 -0.0  0.0 -0.0  0.0 -0.0  0.0 -0.0 -0.0\n",
      "9      0.0 -0.0  0.0 -0.0  0.0 -0.0  0.0  0.0  0.0 -0.0\n",
      "        S1   R1   S2   R2   S3   R3   S4   R4   S5   R5\n",
      "Class                                                  \n",
      "0      1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
      "1      1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
      "2      1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
      "3      1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
      "4      1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
      "5      1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
      "6      1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
      "7      1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
      "8      1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
      "9      1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n"
     ]
    }
   ],
   "source": [
    "poker_grouped = poker_hands.groupby('Class')\n",
    "\n",
    "zscore = lambda x: (x - x.mean()) / x.std()\n",
    "\n",
    "# Apply the transformation\n",
    "poker_trans = poker_grouped.transform(zscore)\n",
    "\n",
    "# Re-group the grouped object\n",
    "poker_regrouped = poker_trans.groupby(poker_hands['Class'])\n",
    "\n",
    "# Print each group's means and standard deviation\n",
    "print(np.round(poker_regrouped.mean(), 3))\n",
    "print(poker_regrouped.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data filtration using the filter() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Days of the week that have a mean total_bill greater than $20: ['Sun' 'Sat']\n"
     ]
    }
   ],
   "source": [
    "# Filter the days where the count of total_bill is greater than $40\n",
    "total_bill_40 = restaurant_data.groupby('day').filter(lambda x: x['total_bill'].count() > 40)\n",
    "\n",
    "# Select only the entries that have a mean total_bill greater than $20\n",
    "total_bill_20 = total_bill_40.groupby('day').filter(lambda x : x['total_bill'].mean() > 20)\n",
    "\n",
    "# Print days of the week that have a mean total_bill greater than $20\n",
    "print('Days of the week that have a mean total_bill greater than $20:', total_bill_20.day.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "233px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
